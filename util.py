import aiohttp
import random
from datetime import datetime
from typing import Optional, Dict, Any, List
from pathlib import Path
import json
import asyncio
import re

from cookie import CookieManager
from config import WEBHOOK_URL, PROXY_URL, USE_PROXY
from emoji import get_emoji_and_type

# User-Agentæ± 
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:120.0) Gecko/20100101 Firefox/120.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0"
]

# æ–‡ä»¶è·¯å¾„ç›¸å…³é…ç½®
DATA_DIR = Path("data")
DATA_DIR.mkdir(exist_ok=True)

# æ–‡ä»¶åé…ç½®
LISTING_RAW_FILE = "listing_raw.html"
LISTING_PARSED_FILE = "listing_parsed.json"

# æ·»åŠ é”™è¯¯æ¨é€é™åˆ¶ç›¸å…³çš„å…¨å±€å˜é‡
ERROR_MSG_LIMIT = 5  # æ¯ä¸ªæ—¶é—´çª—å£å†…çš„æœ€å¤§é”™è¯¯æ¨é€æ¬¡æ•°
ERROR_MSG_WINDOW = 3600  # æ—¶é—´çª—å£å¤§å°(ç§’)
error_msg_count = 0
last_error_reset_time = datetime.now()

# åˆå§‹åŒ–CookieManager
cookie_manager = CookieManager()

def build_article_link(title: str, code: str) -> str:
    """æ„å»ºæ–‡ç« é“¾æ¥
    
    Args:
        title: æ–‡ç« æ ‡é¢˜
        code: æ–‡ç« code(ä¸æ˜¯id)
        
    Returns:
        æ ¼å¼åŒ–åçš„æ–‡ç« é“¾æ¥
    """
    base_url = "https://www.binance.com/en/support/announcement/"
    
    # å¤„ç†æ ‡é¢˜æ ¼å¼
    formatted_title = title.lower()
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç§»é™¤ç‰¹å®šæ ‡ç‚¹ç¬¦å·ï¼Œå°†æ’‡å·æ›¿æ¢ä¸ºè¿å­—ç¬¦
    formatted_title = re.sub(r'[()!?.,:â€œâ€#&]', '', formatted_title)
    formatted_title = formatted_title.replace("'", "-")
    # å°†è¿ç»­çš„ç©ºæ ¼æ›¿æ¢ä¸ºå•ä¸ªç ´æŠ˜å·
    formatted_title = re.sub(r'\s+', '-', formatted_title)
    
    return f"{base_url}{formatted_title}-{code}"

def build_message(title: str, 
                 release_date: str, 
                 link: str
                 ) -> str:
    """æ„å»ºé€šç”¨çš„æ¨é€æ¶ˆæ¯
    
    Args:
        title: å…¬å‘Šæ ‡é¢˜
        release_date: å‘å¸ƒæ—¶é—´
        link: æ–‡ç« é“¾æ¥
        
    Returns:
        æ ¼å¼åŒ–çš„æ¶ˆæ¯å­—ç¬¦ä¸²
    """
    emoji, type = get_emoji_and_type(title)
    
    return (
        f"{emoji} {type}\n"
        f"ğŸ“Œ: {title}\n"
        f"ğŸ•’: {release_date}\n"
        f"ğŸ”—: {link if link else 'æ— é“¾æ¥'}"
    )

async def send_message_async(message_content: str, is_error: bool = False) -> None:
    """å‘é€æ¶ˆæ¯åˆ°ä¼ä¸šå¾®ä¿¡æœºå™¨äºº
    
    Args:
        message_content: è¦å‘é€çš„æ¶ˆæ¯å†…å®¹
        is_error: æ˜¯å¦ä¸ºé”™è¯¯æ¶ˆæ¯
    """
    global error_msg_count, last_error_reset_time
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®é”™è¯¯è®¡æ•°
    now = datetime.now()
    if (now - last_error_reset_time).total_seconds() >= ERROR_MSG_WINDOW:
        error_msg_count = 0
        last_error_reset_time = now
    
    # å¦‚æœæ˜¯é”™è¯¯æ¶ˆæ¯ä¸”å·²è¾¾åˆ°é™åˆ¶,åˆ™åªè®°å½•æ—¥å¿—
    if is_error:
        if error_msg_count >= ERROR_MSG_LIMIT:
            log_with_time(f"Error message suppressed (limit reached): {message_content}")
            return
        error_msg_count += 1
        
    headers = {'Content-Type': 'application/json'}
    payload = {
        "msgtype": "text",
        "text": {
            "content": message_content
        }
    }
    
    log_with_time(f"Sending message: {message_content}")

    proxy = PROXY_URL if USE_PROXY else None
    async with aiohttp.ClientSession() as session:
        async with session.post(WEBHOOK_URL, json=payload, headers=headers, proxy=proxy) as response:
            if response.status == 200:
                log_with_time("Message sent successfully!")
            else:
                log_with_time(f"Failed to send message: {response.status}")

def log_with_time(message: str, module: str = '') -> None:
    """æ‰“å°å¸¦æ—¶é—´æˆ³å’Œæ¨¡å—åçš„æ¶ˆæ¯"""
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{current_time}] {message}")

async def get_headers(referer: str = '') -> Dict[str, str]:
    """ç”Ÿæˆè¯·æ±‚å¤´,æ”¯æŒè‡ªåŠ¨æ›´æ–°cookie"""
    cookie = cookie_manager.get_cookies()
    if not cookie:
        try:
            cookie = await cookie_manager.update_cookies()
        except Exception as e:
            log_with_time(f"Failed to get cookies: {e}")
            raise
    
    return {
        'authority': 'www.binance.com',
        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
        'accept-encoding': 'gzip, deflate, br, zstd',
        'accept-language': 'zh-CN,zh;q=0.9,en;q=0.8,zh-TW;q=0.7',
        'cache-control': 'max-age=0',
        'User-Agent': random.choice(USER_AGENTS),
        'cookie': cookie,
        'sec-ch-ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Windows"',
        'sec-fetch-dest': 'document',
        'sec-fetch-mode': 'navigate',
        'sec-fetch-site': 'same-origin',
        'sec-fetch-user': '?1',
        'upgrade-insecure-requests': '1'
    }

async def fetch_and_save_html_content(url: str, filename: str, max_retries: int = 3) -> Optional[str]:
    """è·å–å¹¶ä¿å­˜HTMLå†…å®¹,æ”¯æŒcookieè‡ªåŠ¨æ›´æ–°"""
    for attempt in range(max_retries):
        try:
            headers = await get_headers()
            log_with_time(f"Starting request to {url}")
            log_with_time(f"Using cookie: {headers['cookie'][:50]}...")
            
            proxy = PROXY_URL if USE_PROXY else None
            log_with_time(f"Attempt {attempt + 1}/{max_retries} with proxy: {proxy}")
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, headers=headers, proxy=proxy) as response:
                    log_with_time(f"ğŸ”„ Response status: {response.status}")
                    
                    if response.status == 202:
                        log_with_time("ğŸ”‘ Cookie expired, updating...")
                        await cookie_manager.update_cookies()
                        continue
                        
                    if response.status == 200:
                        content = await response.text()
                        
                        # ä¿å­˜å†…å®¹åˆ°æ–‡ä»¶
                        file_path = DATA_DIR / filename
                        file_path.write_text(content, encoding='utf-8')
                        log_with_time(f"ğŸ’¾ Content saved to {file_path}")
                        
                        return content
                    else:
                        log_with_time(f"âŒ Request failed with status: {response.status}")
                        
        except Exception as e:
            log_with_time(f"Error in attempt {attempt + 1}: {e}")
            if attempt == max_retries - 1:
                raise
            
        await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
    
    return None

def save_html_content(response_text: str, filename: str) -> None:
    """ä¿å­˜HTMLå†…å®¹åˆ°dataç›®å½•ä¸‹çš„æ–‡ä»¶
    
    Args:
        response_text: è¦ä¿å­˜çš„HTMLå†…å®¹
        filename: æ–‡ä»¶å
    """
    try:
        file_path = DATA_DIR / filename
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(response_text)
        log_with_time(f"Raw HTML saved to {file_path}")
    except Exception as e:
        log_with_time(f"Error saving HTML content: {e}")

def get_last_articles_from_file(filename: str = LISTING_PARSED_FILE) -> set:
    """ä»æœ¬åœ°JSONæ–‡ä»¶ä¸­è¯»å–ä¸Šæ¬¡çš„æ–‡ç« IDé›†åˆ
    
    Args:
        filename: JSONæ–‡ä»¶åï¼Œé»˜è®¤ä¸º"listing_parsed.json"
        
    Returns:
        æ–‡ç« IDé›†åˆ
    """
    try:
        json_path = DATA_DIR / filename
        if not json_path.exists():
            log_with_time(f"No existing file found at {json_path}")
            return set()
            
        with open(json_path, 'r', encoding='utf-8') as f:
            json_data = json.load(f)
            
        # æŸ¥æ‰¾åŒ…å« catalogDetail çš„è·¯ç”±
        for route_content in json_data['appState']['loader']['dataByRouteId'].values():
            if 'catalogDetail' in route_content:
                articles = route_content['catalogDetail']['articles']
                log_with_time(f"Loaded {len(articles)} articles from {filename}")
                return {article['id'] for article in articles}
                
        log_with_time(f"No articles found in {filename}")
        return set()
    except Exception as e:
        log_with_time(f"Error reading last articles from file: {e}")
        return set()