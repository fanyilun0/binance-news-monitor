import asyncio
import json
import re
from typing import Optional, List, Dict, Any
from datetime import datetime, timedelta
from collections import deque

from config import ALWAYS_NOTIFY, LISTING_API_URL, MONITOR_INTERVAL
from util import (
    DATA_DIR,
    LISTING_RAW_FILE,
    LISTING_PARSED_FILE,
    send_message_async,
    log_with_time,
    build_article_link,
    build_message,
    fetch_and_save_html_content,
)

last_article_ids = set()

ERROR_WINDOW = timedelta(minutes=15)  # é”™è¯¯æ£€æµ‹æ—¶é—´çª—å£
ERROR_THRESHOLD = 10  # é”™è¯¯æ¬¡æ•°é˜ˆå€¼
error_times = deque()  # å­˜å‚¨é”™è¯¯å‘ç”Ÿæ—¶é—´çš„é˜Ÿåˆ—

def parse_listing_data(html_content: str) -> Optional[tuple[List[Dict[str, Any]], List[Dict[str, Any]]]]:
    """ä»HTMLå†…å®¹ä¸­è§£æå‡ºæ–°å¸ä¸Šçº¿ä¿¡æ¯,è¿”å›(articles, latest_articles)å…ƒç»„"""
    try:
        # æŸ¥æ‰¾åŒ…å«ç›®æ ‡æ•°æ®çš„scriptæ ‡ç­¾
        pattern = r'<script id="__APP_DATA" type="application/json".*?>(.*?)</script>'
        script_content = re.search(pattern, html_content, re.DOTALL)
        
        if not script_content:
            log_with_time("ğŸ”´ No APP_DATA script found")
            return None
            
        # è§£æJSONæ•°æ®
        json_data = json.loads(script_content.group(1))
        
        # ä¿å­˜è§£æåçš„JSONæ•°æ®åˆ°dataç›®å½•
        json_path = DATA_DIR / LISTING_PARSED_FILE
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        log_with_time(f"Parsed JSON saved to {json_path}")

        # æŸ¥æ‰¾åŒ…å« catalogDetail çš„è·¯ç”±
        route_data = None
        for route_content in json_data['appState']['loader']['dataByRouteId'].values():
            if 'catalogDetail' in route_content:
                route_data = route_content
                break
                
        if not route_data:
            log_with_time("ğŸ”´ No route with catalogDetail found") 
            return None
            
        # è·å–ä¸¤ä¸ªåˆ—è¡¨
        articles = route_data['catalogDetail']['articles']
        latest_articles = route_data.get('latestArticles', [])
        
        # ç»Ÿä¸€æ—¶é—´å­—æ®µ
        for article in latest_articles:
            article['releaseDate'] = article.pop('publishDate', 0)
            
        return articles, latest_articles
        
    except Exception as e:
        log_with_time(f"ğŸ”´ Error parsing listing data: {e}")
        return None

async def save_and_parse_listings() -> Optional[tuple[List[Dict[str, Any]], List[Dict[str, Any]]]]:
    response_text = await fetch_and_save_html_content(LISTING_API_URL, LISTING_RAW_FILE)
    if response_text is None:
        return None
    return parse_listing_data(response_text)

async def send_new_article_notifications(articles: List[Dict[str, Any]], 
                                       new_ids: set,
                                       is_initial: bool = False) -> None:
    """å‘é€æ–°æ–‡ç« é€šçŸ¥"""
    for article in articles:
        if article['id'] in new_ids:
            formatted_date = datetime.fromtimestamp(
                article['releaseDate']/1000
            ).strftime('%Y-%m-%d %H:%M:%S')
            
            message = build_message(
                title=article['title'],
                release_date=formatted_date,
                link=build_article_link(article['title'], article['code']),
            )
            await send_message_async(message)

async def monitor() -> None:
    """ç›‘æ§æ–°å¸ä¸Šçº¿å…¬å‘Š"""
    global last_article_ids, error_times
    log_with_time("ğŸŸ¢ Starting Binance listing monitor...")
    
    while True:
        try:
            # æ£€æŸ¥æ–°æ–‡ç« 
            result = await save_and_parse_listings()
            if result is None:
                log_with_time("ğŸ”´ No articles found in this check")
                await asyncio.sleep(MONITOR_INTERVAL)
                continue
                
            articles, latest_articles = result
            # åˆå¹¶ä¸¤ä¸ªåˆ—è¡¨
            all_articles = articles + latest_articles

            # è·å–æ‰€æœ‰æ–‡ç« çš„IDé›†åˆ
            current_article_ids = {article['id'] for article in all_articles}
            
            # é¦–æ¬¡æ‰§è¡Œæ—¶,è¾“å‡ºè¯¦ç»†ä¿¡æ¯
            if len(last_article_ids) == 0:
                log_with_time("ğŸ”µ First run, printing all current articles:")
                for article in articles:
                    formatted_date = datetime.fromtimestamp(
                        article['releaseDate']/1000
                    ).strftime('%Y-%m-%d %H:%M:%S')
                    log_with_time(f"ğŸ“„ {formatted_date} - [Listing] {article['title']}")
                for article in latest_articles:
                    formatted_date = datetime.fromtimestamp(
                        article['releaseDate']/1000
                    ).strftime('%Y-%m-%d %H:%M:%S')
                    log_with_time(f"ğŸ“„ {formatted_date} - [News] {article['title']}")
                last_article_ids = current_article_ids
                if ALWAYS_NOTIFY:
                    log_with_time("ğŸ”” ALWAYS_NOTIFY is True, sending initial notifications...")
                    await send_new_article_notifications(all_articles, current_article_ids, True)
                continue
            
            # æ‰¾å‡ºæ–°æ–‡ç« ID
            new_article_ids = current_article_ids - last_article_ids
            
            if new_article_ids:
                log_with_time(f"ğŸŸ¢ Found {len(new_article_ids)} new articles")
                for article in articles:
                    if article['id'] in new_article_ids:
                        log_with_time(f"ğŸŸ¢ Article: [Listing] {article['title']}")
                for article in latest_articles:
                    if article['id'] in new_article_ids:
                        log_with_time(f"ğŸŸ¢ Article: [News] {article['title']}")
                await send_new_article_notifications(all_articles, new_article_ids, False)
            
            # æ›´æ–°ä¸Šæ¬¡çš„æ–‡ç« IDé›†åˆ
            last_article_ids = current_article_ids
            
        except Exception as e:
            current_time = datetime.now()
            # æ¸…ç†è¶…è¿‡æ—¶é—´çª—å£çš„é”™è¯¯è®°å½•
            while error_times and current_time - error_times[0] > ERROR_WINDOW:
                error_times.popleft()
            
            # æ·»åŠ å½“å‰é”™è¯¯æ—¶é—´
            error_times.append(current_time)
            
            # è®°å½•é”™è¯¯æ—¥å¿—
            log_with_time(f"ğŸ”´ Error in monitor loop: {e}")
            
            # åªæœ‰åœ¨æ—¶é—´çª—å£å†…é”™è¯¯æ¬¡æ•°è¾¾åˆ°é˜ˆå€¼æ—¶æ‰å‘é€é€šçŸ¥
            if len(error_times) >= ERROR_THRESHOLD:
                await send_message_async(
                    f"âŒ Monitor News Error", 
                    is_error=True
                )
        
        await asyncio.sleep(MONITOR_INTERVAL)

if __name__ == "__main__":
    asyncio.run(monitor())
